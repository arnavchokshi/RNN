Memorizing Music using Recurrent Neural Networks for Explainable Artificial Intelligence

As artificial intelligence (AI) continues to evolve, it is becoming increasingly complex due to the ever expanding use of neural networks. Dangers can arise through this lack of understanding in AIs algorithm, as AIs diverse usage can cause false detection of medical conditions, sexism in language translation, and unethical justice rulings to name a few (Pazzanese 2020). Specifically, Recurrent Neural Networks (RNNs), which are a type of neural network that are well-suited for tasks such as image recognition and natural language processing, are especially difficult to understand (Donges, 2021). Being a major issue in the field of AI, this study aimed to find the limitations of Explainable AI in the specific case of an RNN tasked with music memorization by using the equation of an RNN and analyzing the bias and weight matrices (The Royal Society, 2019). Compositions of music that will be memorized vary in size and complexity. Ultimately, the only compositions that could accurately be memorized and explained were pieces that had a linear progression. In contribution to explainable AI, this study provides insight as to how the method of weight and bias analysis remains unable to explain most cases of music memorization and how only models based on compositions with a linear pattern can be explained (Donges, 2021).  

